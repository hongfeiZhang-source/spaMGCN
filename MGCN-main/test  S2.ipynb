{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-28 14:34:41.705465: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-03-28 14:34:41.881160: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-28 14:34:42.477555: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib:\n",
      "2025-03-28 14:34:42.477648: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib:\n",
      "2025-03-28 14:34:42.477657: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from utils.misc import *\n",
    "from train.train import Train,Test\n",
    "from datasets.data_utils import load_dataset\n",
    "from model.Creat_model import creat_model\n",
    "from utils.preprocess import *\n",
    "from utils.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.backends import cudnn\n",
    "def fix_seed(seed):\n",
    "    #seed = 2023\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    cudnn.deterministic = True\n",
    "    cudnn.benchmark = False\n",
    "    \n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx\n",
    "import torch\n",
    "import scipy.sparse as sp\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from munkres import Munkres\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import adjusted_rand_score as ari_score\n",
    "from sklearn.metrics.cluster import normalized_mutual_info_score as nmi_score\n",
    "from sklearn.decomposition import PCA\n",
    "from torch.utils.data import Dataset\n",
    "import argparse\n",
    "import yaml\n",
    "from torch_geometric.utils.convert import to_networkx\n",
    "import pynvml\n",
    "\n",
    "def build_args():\n",
    "    \n",
    "    parser = argparse.ArgumentParser(formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
    "    parser.add_argument('--dataset', type=str, default=\"acm\")\n",
    "    parser.add_argument('--seed', type=int, default=20)\n",
    "    parser.add_argument('--cuda', type=bool, default=True)\n",
    "    parser.add_argument('--n_input', type=int, default=None)\n",
    "    parser.add_argument('--n_z', type=int, default=None)\n",
    "    parser.add_argument('--freedom_degree', type=float, default=1.0)\n",
    "    parser.add_argument('--epoch', type=int, default=None)\n",
    "    parser.add_argument('--shuffle', type=bool, default=True)\n",
    "    parser.add_argument('--sigma', type=float, default=None)\n",
    "    parser.add_argument('--loss_n', type=float, default=None)\n",
    "    parser.add_argument('--loss_w', type=float, default=None)\n",
    "    parser.add_argument('--loss_s', type=float, default=None)\n",
    "    parser.add_argument('--loss_a', type=float, default=None)\n",
    "    parser.add_argument('--lr', type=float, default=1e-4)\n",
    "    parser.add_argument('--acc', type=float, default=-1)\n",
    "    parser.add_argument('--f1', type=float, default=-1)\n",
    "    args = parser.parse_args([])\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca(adata, use_reps=None, n_comps=10):\n",
    "    \n",
    "    \"\"\"Dimension reduction with PCA algorithm\"\"\"\n",
    "    \n",
    "    from sklearn.decomposition import PCA\n",
    "    from scipy.sparse.csc import csc_matrix\n",
    "    from scipy.sparse.csr import csr_matrix\n",
    "    pca = PCA(n_components=n_comps)\n",
    "    if use_reps is not None:\n",
    "       feat_pca = pca.fit_transform(adata.obsm[use_reps])\n",
    "    else: \n",
    "       if isinstance(adata.X, csc_matrix) or isinstance(adata.X, csr_matrix):\n",
    "          feat_pca = pca.fit_transform(adata.X.toarray()) \n",
    "       else:   \n",
    "          feat_pca = pca.fit_transform(adata.X)\n",
    "    \n",
    "    return feat_pca\n",
    "\n",
    "def clr_normalize_each_cell(adata, inplace=True):\n",
    "    \n",
    "    \"\"\"Normalize count vector for each cell, i.e. for each row of .X\"\"\"\n",
    "\n",
    "    import numpy as np\n",
    "    import scipy\n",
    "\n",
    "    def seurat_clr(x):\n",
    "        # TODO: support sparseness\n",
    "        s = np.sum(np.log1p(x[x > 0]))\n",
    "        exp = np.exp(s / len(x))\n",
    "        return np.log1p(x / exp)\n",
    "\n",
    "    if not inplace:\n",
    "        adata = adata.copy()\n",
    "    \n",
    "    # apply to dense or sparse matrix, along axis. returns dense matrix\n",
    "    adata.X = np.apply_along_axis(\n",
    "        seurat_clr, 1, (adata.X.A if scipy.sparse.issparse(adata.X) else np.array(adata.X))\n",
    "    )\n",
    "    return adata     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load configs\n"
     ]
    }
   ],
   "source": [
    "args = build_args()\n",
    "args = load_configs(args, \"config/configs.yml\")\n",
    "# set_random_seed(2024)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 淋巴结\n",
    "import scanpy as sc\n",
    "adata_omics1 = sc.read_h5ad( '/home/hfzhang/data/空间转录组/Human_lymph_node/slice2/s2_adata_rna.h5ad')\n",
    "adata_omics2 = sc.read_h5ad('/home/hfzhang/data/空间转录组/Human_lymph_node/slice2/s2_adata_adt.h5ad')\n",
    "\n",
    "adata_omics1.var_names_make_unique()\n",
    "adata_omics2.var_names_make_unique()\n",
    "adata_omics1 = adata_omics1[adata_omics1.obs['final_annot'].notna()]  \n",
    "adata_omics2 = adata_omics2[adata_omics2.obs['final_annot'].notna()] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hfzhang/software/anaconda3/envs/GraphST/lib/python3.8/site-packages/scanpy/preprocessing/_simple.py:250: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual.\n",
      "  adata.var['n_cells'] = number\n",
      "/tmp/ipykernel_25511/529664883.py:6: DeprecationWarning: Please use `csc_matrix` from the `scipy.sparse` namespace, the `scipy.sparse.csc` namespace is deprecated.\n",
      "  from scipy.sparse.csc import csc_matrix\n",
      "/tmp/ipykernel_25511/529664883.py:7: DeprecationWarning: Please use `csr_matrix` from the `scipy.sparse` namespace, the `scipy.sparse.csr` namespace is deprecated.\n",
      "  from scipy.sparse.csr import csr_matrix\n",
      "/home/hfzhang/software/anaconda3/envs/GraphST/lib/python3.8/site-packages/scanpy/preprocessing/_simple.py:843: UserWarning: Received a view of an AnnData. Making a copy.\n",
      "  view_to_actual(adata)\n",
      "/tmp/ipykernel_25511/529664883.py:6: DeprecationWarning: Please use `csc_matrix` from the `scipy.sparse` namespace, the `scipy.sparse.csc` namespace is deprecated.\n",
      "  from scipy.sparse.csc import csc_matrix\n",
      "/tmp/ipykernel_25511/529664883.py:7: DeprecationWarning: Please use `csr_matrix` from the `scipy.sparse` namespace, the `scipy.sparse.csr` namespace is deprecated.\n",
      "  from scipy.sparse.csr import csr_matrix\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# RNA\n",
    "sc.pp.filter_genes(adata_omics1, min_cells=10)\n",
    "sc.pp.highly_variable_genes(adata_omics1, flavor=\"seurat_v3\", n_top_genes=3000)\n",
    "sc.pp.normalize_total(adata_omics1, target_sum=1e4)\n",
    "sc.pp.log1p(adata_omics1)\n",
    "sc.pp.scale(adata_omics1)\n",
    "\n",
    "adata_omics1 =  adata_omics1[:, adata_omics1.var['highly_variable']]\n",
    "adata_omics1.obsm['feat'] = pca(adata_omics1, n_comps=adata_omics2.n_vars-1)\n",
    "# Protein\n",
    "adata_omics2 = clr_normalize_each_cell(adata_omics2)\n",
    "sc.pp.scale(adata_omics2)\n",
    "adata_omics2.obsm['feat'] = pca(adata_omics2, n_comps=adata_omics2.n_vars-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_adj(adata):\n",
    "    cell_position_omics1 = adata.obsm['spatial']\n",
    "    adj_omics1 = construct_graph_by_coordinate(cell_position_omics1, n_neighbors=3)\n",
    "    adata.uns['adj_spatial'] = adj_omics1\n",
    "    adj_spatial_omics1 = adata.uns['adj_spatial']\n",
    "    adj_spatial_omics1 = transform_adjacent_matrix(adj_spatial_omics1)\n",
    "    adj_spatial_omics1 = adj_spatial_omics1.toarray()\n",
    "    adj_spatial_omics1 = adj_spatial_omics1 + adj_spatial_omics1.T\n",
    "    adj_spatial_omics1 = np.where(adj_spatial_omics1>1, 1, adj_spatial_omics1)\n",
    "    adj = preprocess_graph(adj_spatial_omics1)\n",
    "    return adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "label=adata_omics2.obs['final_annot'].values\n",
    "classes, label = np.unique(label, return_inverse=True)\n",
    "classes = classes.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.n_input=adata_omics2.n_vars-1\n",
    "args.n_input1=adata_omics2.n_vars-1\n",
    "args.n_clusters=len(classes)\n",
    "device='cuda:0'\n",
    "args.n_clusters\n",
    "random_seek=2020\n",
    "args.Type='10x'\n",
    "args.loss_n=0.001\n",
    "args.epoch=600\n",
    "args.n_clusters=len(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_seed(random_seek)\n",
    "args.random_seed=random_seek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  9 loss: 6.4762654304504395\n",
      "Epoch_  9 , nmi 0.3074 , ari 0.1757 , ami 0.3028 , homogeneity 0.3367 , completeness 0.2827 , v_measure 0.3074\n",
      " 19 loss: 6.456779479980469\n",
      "Epoch_ 19 , nmi 0.3175 , ari 0.1845 , ami 0.3130 , homogeneity 0.3472 , completeness 0.2925 , v_measure 0.3175\n",
      " 29 loss: 6.4343485832214355\n",
      "Epoch_ 29 , nmi 0.3293 , ari 0.1898 , ami 0.3248 , homogeneity 0.3629 , completeness 0.3014 , v_measure 0.3293\n",
      " 39 loss: 6.405903339385986\n",
      "Epoch_ 39 , nmi 0.3252 , ari 0.1800 , ami 0.3207 , homogeneity 0.3554 , completeness 0.2997 , v_measure 0.3252\n",
      " 49 loss: 6.368572235107422\n",
      "Epoch_ 49 , nmi 0.3127 , ari 0.1796 , ami 0.3081 , homogeneity 0.3408 , completeness 0.2888 , v_measure 0.3127\n",
      " 59 loss: 6.319760799407959\n",
      "Epoch_ 59 , nmi 0.3047 , ari 0.1750 , ami 0.3000 , homogeneity 0.3334 , completeness 0.2805 , v_measure 0.3047\n",
      " 69 loss: 6.264246463775635\n",
      "Epoch_ 69 , nmi 0.3064 , ari 0.1755 , ami 0.3018 , homogeneity 0.3347 , completeness 0.2826 , v_measure 0.3064\n",
      " 79 loss: 6.183712959289551\n",
      "Epoch_ 79 , nmi 0.3061 , ari 0.1772 , ami 0.3015 , homogeneity 0.3351 , completeness 0.2818 , v_measure 0.3061\n",
      " 89 loss: 6.083553314208984\n",
      "Epoch_ 89 , nmi 0.3035 , ari 0.1752 , ami 0.2988 , homogeneity 0.3321 , completeness 0.2793 , v_measure 0.3035\n",
      " 99 loss: 5.962852478027344\n",
      "Epoch_ 99 , nmi 0.3023 , ari 0.1767 , ami 0.2977 , homogeneity 0.3311 , completeness 0.2781 , v_measure 0.3023\n",
      "109 loss: 5.823148727416992\n",
      "Epoch_109 , nmi 0.3009 , ari 0.1758 , ami 0.2963 , homogeneity 0.3301 , completeness 0.2764 , v_measure 0.3009\n",
      "119 loss: 5.668557643890381\n",
      "Epoch_119 , nmi 0.3006 , ari 0.1751 , ami 0.2960 , homogeneity 0.3300 , completeness 0.2761 , v_measure 0.3006\n",
      "129 loss: 5.507475852966309\n",
      "Epoch_129 , nmi 0.3019 , ari 0.1775 , ami 0.2973 , homogeneity 0.3315 , completeness 0.2772 , v_measure 0.3019\n",
      "139 loss: 5.351980209350586\n",
      "Epoch_139 , nmi 0.3000 , ari 0.1777 , ami 0.2954 , homogeneity 0.3295 , completeness 0.2753 , v_measure 0.3000\n",
      "149 loss: 5.213339805603027\n",
      "Epoch_149 , nmi 0.2995 , ari 0.1859 , ami 0.2949 , homogeneity 0.3284 , completeness 0.2753 , v_measure 0.2995\n",
      "159 loss: 5.097180366516113\n",
      "Epoch_159 , nmi 0.3069 , ari 0.1899 , ami 0.3023 , homogeneity 0.3356 , completeness 0.2827 , v_measure 0.3069\n",
      "169 loss: 5.001307487487793\n",
      "Epoch_169 , nmi 0.3092 , ari 0.1914 , ami 0.3046 , homogeneity 0.3380 , completeness 0.2850 , v_measure 0.3092\n",
      "179 loss: 4.918457508087158\n",
      "Epoch_179 , nmi 0.3137 , ari 0.1928 , ami 0.3091 , homogeneity 0.3434 , completeness 0.2887 , v_measure 0.3137\n",
      "189 loss: 4.842111587524414\n",
      "Epoch_189 , nmi 0.3158 , ari 0.1898 , ami 0.3113 , homogeneity 0.3463 , completeness 0.2903 , v_measure 0.3158\n",
      "199 loss: 4.769091606140137\n",
      "Epoch_199 , nmi 0.3257 , ari 0.2011 , ami 0.3211 , homogeneity 0.3542 , completeness 0.3014 , v_measure 0.3257\n",
      "209 loss: 4.698757648468018\n",
      "Epoch_209 , nmi 0.3281 , ari 0.2024 , ami 0.3236 , homogeneity 0.3570 , completeness 0.3036 , v_measure 0.3281\n",
      "219 loss: 4.631438732147217\n",
      "Epoch_219 , nmi 0.3358 , ari 0.2060 , ami 0.3313 , homogeneity 0.3642 , completeness 0.3115 , v_measure 0.3358\n",
      "229 loss: 4.567329406738281\n",
      "Epoch_229 , nmi 0.3396 , ari 0.2073 , ami 0.3351 , homogeneity 0.3686 , completeness 0.3148 , v_measure 0.3396\n",
      "239 loss: 4.5064167976379395\n",
      "Epoch_239 , nmi 0.3500 , ari 0.2116 , ami 0.3456 , homogeneity 0.3802 , completeness 0.3242 , v_measure 0.3500\n",
      "249 loss: 4.448764324188232\n",
      "Epoch_249 , nmi 0.3573 , ari 0.2232 , ami 0.3530 , homogeneity 0.3877 , completeness 0.3314 , v_measure 0.3573\n",
      "259 loss: 4.393861770629883\n",
      "Epoch_259 , nmi 0.3624 , ari 0.2264 , ami 0.3581 , homogeneity 0.3931 , completeness 0.3362 , v_measure 0.3624\n",
      "269 loss: 4.34120512008667\n",
      "Epoch_269 , nmi 0.3647 , ari 0.2295 , ami 0.3604 , homogeneity 0.3956 , completeness 0.3382 , v_measure 0.3647\n",
      "279 loss: 4.290134429931641\n",
      "Epoch_279 , nmi 0.3670 , ari 0.2313 , ami 0.3628 , homogeneity 0.3983 , completeness 0.3403 , v_measure 0.3670\n",
      "289 loss: 4.240140914916992\n",
      "Epoch_289 , nmi 0.3669 , ari 0.2310 , ami 0.3627 , homogeneity 0.3980 , completeness 0.3404 , v_measure 0.3669\n",
      "299 loss: 4.190895080566406\n",
      "Epoch_299 , nmi 0.3682 , ari 0.2342 , ami 0.3640 , homogeneity 0.3986 , completeness 0.3422 , v_measure 0.3682\n",
      "309 loss: 4.142190456390381\n",
      "Epoch_309 , nmi 0.3753 , ari 0.2386 , ami 0.3711 , homogeneity 0.4065 , completeness 0.3485 , v_measure 0.3753\n",
      "319 loss: 4.09382438659668\n",
      "Epoch_319 , nmi 0.3756 , ari 0.2483 , ami 0.3714 , homogeneity 0.4053 , completeness 0.3500 , v_measure 0.3756\n",
      "329 loss: 4.0457234382629395\n",
      "Epoch_329 , nmi 0.3773 , ari 0.2504 , ami 0.3731 , homogeneity 0.4075 , completeness 0.3513 , v_measure 0.3773\n",
      "339 loss: 3.997725009918213\n",
      "Epoch_339 , nmi 0.3781 , ari 0.2509 , ami 0.3739 , homogeneity 0.4068 , completeness 0.3532 , v_measure 0.3781\n",
      "349 loss: 3.9496893882751465\n",
      "Epoch_349 , nmi 0.3755 , ari 0.2508 , ami 0.3713 , homogeneity 0.4041 , completeness 0.3507 , v_measure 0.3755\n",
      "359 loss: 3.9014575481414795\n",
      "Epoch_359 , nmi 0.3760 , ari 0.2512 , ami 0.3717 , homogeneity 0.4043 , completeness 0.3514 , v_measure 0.3760\n",
      "369 loss: 3.8530805110931396\n",
      "Epoch_369 , nmi 0.3739 , ari 0.2489 , ami 0.3696 , homogeneity 0.4018 , completeness 0.3496 , v_measure 0.3739\n",
      "379 loss: 3.804567575454712\n",
      "Epoch_379 , nmi 0.3756 , ari 0.2500 , ami 0.3714 , homogeneity 0.4033 , completeness 0.3515 , v_measure 0.3756\n",
      "389 loss: 3.755981683731079\n",
      "Epoch_389 , nmi 0.3749 , ari 0.2487 , ami 0.3707 , homogeneity 0.4025 , completeness 0.3509 , v_measure 0.3749\n",
      "399 loss: 3.7075250148773193\n",
      "Epoch_399 , nmi 0.3765 , ari 0.2561 , ami 0.3723 , homogeneity 0.4035 , completeness 0.3529 , v_measure 0.3765\n",
      "409 loss: 3.659510850906372\n",
      "Epoch_409 , nmi 0.3756 , ari 0.2550 , ami 0.3713 , homogeneity 0.4025 , completeness 0.3521 , v_measure 0.3756\n",
      "419 loss: 3.612004518508911\n",
      "Epoch_419 , nmi 0.3745 , ari 0.2675 , ami 0.3702 , homogeneity 0.3888 , completeness 0.3612 , v_measure 0.3745\n",
      "429 loss: 3.5648245811462402\n",
      "Epoch_429 , nmi 0.3754 , ari 0.2550 , ami 0.3711 , homogeneity 0.4015 , completeness 0.3525 , v_measure 0.3754\n",
      "439 loss: 3.5177600383758545\n",
      "Epoch_439 , nmi 0.3750 , ari 0.2689 , ami 0.3706 , homogeneity 0.3880 , completeness 0.3629 , v_measure 0.3750\n",
      "449 loss: 3.4704442024230957\n",
      "Epoch_449 , nmi 0.3769 , ari 0.2719 , ami 0.3725 , homogeneity 0.3899 , completeness 0.3647 , v_measure 0.3769\n",
      "459 loss: 3.422773599624634\n",
      "Epoch_459 , nmi 0.3759 , ari 0.2702 , ami 0.3715 , homogeneity 0.3889 , completeness 0.3638 , v_measure 0.3759\n",
      "469 loss: 3.3747897148132324\n",
      "Epoch_469 , nmi 0.3750 , ari 0.2696 , ami 0.3706 , homogeneity 0.3872 , completeness 0.3635 , v_measure 0.3750\n",
      "479 loss: 3.3267014026641846\n",
      "Epoch_479 , nmi 0.3732 , ari 0.2673 , ami 0.3687 , homogeneity 0.3856 , completeness 0.3615 , v_measure 0.3732\n",
      "489 loss: 3.278791666030884\n",
      "Epoch_489 , nmi 0.3767 , ari 0.2708 , ami 0.3724 , homogeneity 0.3893 , completeness 0.3650 , v_measure 0.3767\n",
      "499 loss: 3.231494903564453\n",
      "Epoch_499 , nmi 0.3744 , ari 0.2692 , ami 0.3700 , homogeneity 0.3865 , completeness 0.3630 , v_measure 0.3744\n",
      "509 loss: 3.185133218765259\n",
      "Epoch_509 , nmi 0.3699 , ari 0.2536 , ami 0.3656 , homogeneity 0.3935 , completeness 0.3490 , v_measure 0.3699\n",
      "519 loss: 3.139896869659424\n",
      "Epoch_519 , nmi 0.3755 , ari 0.2700 , ami 0.3711 , homogeneity 0.3863 , completeness 0.3653 , v_measure 0.3755\n",
      "529 loss: 3.095794439315796\n",
      "Epoch_529 , nmi 0.3736 , ari 0.2682 , ami 0.3692 , homogeneity 0.3844 , completeness 0.3634 , v_measure 0.3736\n",
      "539 loss: 3.052818536758423\n",
      "Epoch_539 , nmi 0.3759 , ari 0.2698 , ami 0.3715 , homogeneity 0.3864 , completeness 0.3660 , v_measure 0.3759\n",
      "549 loss: 3.010870933532715\n",
      "Epoch_549 , nmi 0.3781 , ari 0.2696 , ami 0.3737 , homogeneity 0.3886 , completeness 0.3682 , v_measure 0.3781\n",
      "559 loss: 2.9697887897491455\n",
      "Epoch_559 , nmi 0.3613 , ari 0.2421 , ami 0.3568 , homogeneity 0.3798 , completeness 0.3444 , v_measure 0.3613\n",
      "569 loss: 2.9293787479400635\n",
      "Epoch_569 , nmi 0.3730 , ari 0.2662 , ami 0.3686 , homogeneity 0.3827 , completeness 0.3638 , v_measure 0.3730\n",
      "579 loss: 2.889559745788574\n",
      "Epoch_579 , nmi 0.3668 , ari 0.2524 , ami 0.3624 , homogeneity 0.3898 , completeness 0.3463 , v_measure 0.3668\n",
      "589 loss: 2.8503050804138184\n",
      "Epoch_589 , nmi 0.3770 , ari 0.2678 , ami 0.3726 , homogeneity 0.3869 , completeness 0.3675 , v_measure 0.3770\n",
      "599 loss: 2.811683416366577\n",
      "Epoch_599 , nmi 0.3785 , ari 0.2667 , ami 0.3741 , homogeneity 0.3891 , completeness 0.3683 , v_measure 0.3785\n",
      "xunlian\n",
      "name: acm\n",
      "NMI : 0.3785\n",
      "ARI : 0.2667\n",
      "AMI  : 0.3741\n",
      "Epoch_  0 , nmi 0.3802 , ari 0.2705 , ami 0.3758 , homogeneity 0.3915 , completeness 0.3695 , v_measure 0.3802\n",
      "聚类方法为kmeans\n",
      "test\n",
      "name: acm\n",
      "NMI : 0.3802\n",
      "ARI : 0.2705\n",
      "AMI  : 0.3758\n"
     ]
    }
   ],
   "source": [
    "args.n_clusters1=len(set(label))\n",
    "args.n_clusters2=len(set(label))\n",
    "adj_train=create_adj(adata_omics1)\n",
    "adj_train = adj_train.to(device)\n",
    "features_omics1 = torch.FloatTensor(adata_omics1.obsm['feat'].copy()).to(device)\n",
    "features_omics2 = torch.FloatTensor(adata_omics2.obsm['feat'].copy()).to(device)\n",
    "model = creat_model('spamgcn', args).to(device)\n",
    "model=Train(args.epoch, model, features_omics1,features_omics2, adj_train, label, device, args)\n",
    "nmi, ari, ami, homogeneity, completeness, v_measure=Test(model,adata_omics1,features_omics1,features_omics2,adj_train,label,device,args,'kmeans')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GraphST",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
